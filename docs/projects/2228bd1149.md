All-at-once deep learning methods for nonlinear PDE based inverse problems

Project ID: 2228bd1149
(You will need this ID for your application)

Research Theme: [Mathematical Sciences](../themes/mathematical-sciences.md)

UCL Lead department: [Computer Science](../departments/computer-science.md)

[Department Website](https://www.ucl.ac.uk/computer-science)

Lead Supervisor: [Marta Betcke](https://iris.ucl.ac.uk/iris/browse/profile?upi=MMBET00)

Project Summary:

In inverse problems (IPs) a natural role for deep learning (DL) is to encode prior information contained in the training set e.g. anatomical and pathological similarities between patients. Learned reconstruction methods realise this in different ways learning a prior/proximal operator for use within an optimisation scheme or a post-processing correction or a pseudo-inverse e.g. via an unrolled scheme.
 While general PDE solvers are designed to work for all coefficients (in an appropriate function space), for the PDEs modelling the forward operator of a nonlinear IP we may have additional information about the distribution of the coefficients which can be used to improve performance. This idea underpins approaches based on unrolling of an iterative forward solver e.g. GMRES with the net acting as a (flexible) parametric preconditioner and neural operators which directly construct a neural network approximation to the Green’s function as a function of PDE coefficients.
 This project will combine both these strands of research. We will seek to optimise the forward solver’s performance for the coefficients on the manifold of the prior which is akin to adaptivity in classical PDE solvers and combine it optimally with the prior into an inversion procedure. Possible approaches include: i) unrolling a nonlinear solver e.g. Gauss-Newton where the PDE and its adjoint solves are replaced by neural operators and the regularisation functional with a convex neural network (or a primal dual method for non-smooth priors with prox of the regularisation functional replaced with a neural network) and jointly training the assembly on the same training set, ii) training a convex regularisation functional with an unrolled nonlinear solver in an adversarial fashion, iii) PDE constraint optimisation formulation where the PDE and its adjoint solves are expressed in terms of neural operators and trained on the same training set as the regularisation functional.