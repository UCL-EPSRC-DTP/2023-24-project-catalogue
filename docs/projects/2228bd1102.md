###Developing computational methods to minimise social bias in healthcare AI

Project ID: 2228bd1102
(You will need this ID for your application)

Research Theme: [Healthcare Technologies](../themes/healthcare-technologies.md)

UCL Lead department: [Statistical Science](../departments/statistical-science.md)

[Department Website](https://www.ucl.ac.uk/statistics)

Lead Supervisor: [Brieuc Lehmann](https://iris.ucl.ac.uk/iris/browse/profile?upi=BLEHM59)

Project Summary:

Although clinical algorithms have great potential to improve health through better decision making, they also carry the risk of perpetuating existing health inequities that have arisen through social biases. For example, algorithms trained on a particular subset of the population tend to underperform on other parts of the population, leading to poorer clinical decision making for subgroups that have been historically understudied in biomedical research. Machine learning technologies that could mitigate the risk of introducing or exacerbating inequalities include "Human-in-the-loop" structures and adversarial modelling.
 
 The aim of this project is to explore the development of such statistical and machine learning tools for clinical decision support systems. In doing so, the student will gain strong technical skills in statistics and machine learning, particularly around uncertainty quantification in biased datasets. The student will also explore ethical and clinical considerations of specific use cases. The project will focus on diseases whose diagnostic rates vary widely across the population, such as mental health and heart disease, for which these tools have the potential to make a substantial impact.
 
 The student will be supervised by Dr Brieuc Lehmann and Prof Ioanna Manolopoulou. Dr Lehmann is an Assistant Professor in Statistical Science at UCL whose primary research area is health data science, with a particular focus on statistical and machine learning methods for health equity. Prof Manolopoulou is a Professor in Statistical Science at UCL whose main research interests lie in developing, extending or re-evaluating Bayesian models to produce useful and interpretable inferences in practical applications. 
 
 Applicants should have a strong background (e.g. Masterâ€™s degree) in statistics, machine learning or a closely related field, and research interests in one or more of the following: uncertainty quantification, Bayesian statistics, ML-driven decision-making, health equity, ethical AI. Strong statistical programming skills (e.g. R, Python, Julia) are also desirable.